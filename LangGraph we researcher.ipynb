{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph langchain_groq langchain_community -U ddgs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxN18FtbAIEO",
        "outputId": "c80ccd56-c070-4b09-fc66-57e739c64143",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.4)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: langchain_groq in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Collecting ddgs\n",
            "  Downloading ddgs-9.10.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.2.2)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.3.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.12.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: groq<1.0.0,>=0.30.0 in /usr/local/lib/python3.12/dist-packages (from langchain_groq) (0.37.1)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.56)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.12/dist-packages (from ddgs) (8.3.1)\n",
            "Collecting primp>=0.15.0 (from ddgs)\n",
            "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: lxml>=4.9.4 in /usr/local/lib/python3.12/dist-packages (from ddgs) (6.0.2)\n",
            "Requirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\n",
            "Collecting fake-useragent>=2.2.0 (from ddgs)\n",
            "  Downloading fake_useragent-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain_groq) (4.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\n",
            "Requirement already satisfied: brotli in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.2.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\n",
            "Collecting socksio==1.* (from httpx[brotli,http2,socks]>=0.28.1->ddgs)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.12.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Downloading langgraph-1.0.5-py3-none-any.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m157.1/157.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ddgs-9.10.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fake_useragent-2.2.0-py3-none-any.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading langgraph_sdk-0.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: socksio, primp, fake-useragent, langgraph-sdk, ddgs, langgraph\n",
            "  Attempting uninstall: langgraph-sdk\n",
            "    Found existing installation: langgraph-sdk 0.2.15\n",
            "    Uninstalling langgraph-sdk-0.2.15:\n",
            "      Successfully uninstalled langgraph-sdk-0.2.15\n",
            "  Attempting uninstall: langgraph\n",
            "    Found existing installation: langgraph 1.0.4\n",
            "    Uninstalling langgraph-1.0.4:\n",
            "      Successfully uninstalled langgraph-1.0.4\n",
            "Successfully installed ddgs-9.10.0 fake-useragent-2.2.0 langgraph-1.0.5 langgraph-sdk-0.3.0 primp-0.15.0 socksio-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "\n",
        "api_key=userdata.get('GROQ')\n",
        "llm = ChatGroq(\n",
        "            groq_api_key=api_key,\n",
        "            model=\"llama-3.3-70b-versatile\",\n",
        "            temperature=0.0\n",
        "        )\n",
        "search_tool = DuckDuckGoSearchRun()"
      ],
      "metadata": {
        "id": "q8soDfbdAQF5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## State"
      ],
      "metadata": {
        "id": "JdwfYE9OjKex"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1rrCYZkq_mba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9e2bc7ad-68a6-41cc-a708-56e25cecd5a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"question: Stores the original user's question throughout the entire workflow\\nsearch_query: Stores the refined/optimized search query generated by the LLM for better search results\\nsearch_results: Stores the documents/data retrieved from the search/vector database\\nanswer: Stores the final generated response from the LLM\\nneeds_more_info: Boolean flag that determines if we need to search again or if the answer is complete\\niteration_count: Tracks how many times we've looped through the workflow to prevent infinite loops\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Literal\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "import os\n",
        "\n",
        "class ResearchState(TypedDict):\n",
        "  question: str\n",
        "  search_query: str\n",
        "  search_results: list\n",
        "  answer: str\n",
        "  needs_more_info: bool\n",
        "  iteration_count: int\n",
        "\"\"\"question: Stores the original user's question throughout the entire workflow\n",
        "search_query: Stores the refined/optimized search query generated by the LLM for better search results\n",
        "search_results: Stores the documents/data retrieved from the search/vector database\n",
        "answer: Stores the final generated response from the LLM\n",
        "needs_more_info: Boolean flag that determines if we need to search again or if the answer is complete\n",
        "iteration_count: Tracks how many times we've looped through the workflow to prevent infinite loops\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Nodes"
      ],
      "metadata": {
        "id": "C2fO-JWNjUGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_question(state: ResearchState):\n",
        "    \"\"\"Analyzes the question and creates a search query\"\"\"\n",
        "    question = state[\"question\"]\n",
        "    iteration = state.get(\"iteration_count\", 0)\n",
        "\n",
        "    # If first iteration, use original question; otherwise refine\n",
        "    if iteration == 0:\n",
        "        search_query = question\n",
        "    else:\n",
        "        # Refine the query based on previous results\n",
        "        prompt = f\"\"\"\n",
        "        Original question: {question}\n",
        "        Previous search didn't give enough info.\n",
        "        Create a more specific search query to find better results.\n",
        "        Return only the search query, nothing else.\n",
        "        \"\"\"\n",
        "        response = llm.invoke([HumanMessage(content=prompt)])\n",
        "        search_query = response.content.strip()\n",
        "\n",
        "    return {\n",
        "        \"search_query\": search_query,\n",
        "        \"iteration_count\": state.get(\"iteration_count\", 0) + 1\n",
        "    }\n",
        "\n",
        "def search_web(state: ResearchState):\n",
        "    \"\"\"Searches for information using DuckDuckGo\"\"\"\n",
        "    query = state[\"search_query\"]\n",
        "\n",
        "    print(f\"üîç Searching for: {query}\")\n",
        "\n",
        "    try:\n",
        "        # Perform web search\n",
        "        results = search_tool.run(query)\n",
        "        print(f\"‚úÖ Found results (length: {len(results)} chars)\")\n",
        "        return {\"search_results\": results}\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Search failed: {e}\")\n",
        "        return {\"search_results\": f\"Search failed: {str(e)}\"}\n",
        "\n",
        "def generate_answer(state: ResearchState):\n",
        "    \"\"\"Generates answer and checks if it's complete\"\"\"\n",
        "    results = state[\"search_results\"]\n",
        "    question = state[\"question\"]\n",
        "    iteration = state[\"iteration_count\"]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Question: {question}\n",
        "\n",
        "    Search Results:\n",
        "    {results}\n",
        "\n",
        "    Based on the search results above, provide a comprehensive answer to the question.\n",
        "\n",
        "    Important:\n",
        "    - If the search results provide enough information, give a complete answer.\n",
        "    - If you don't have enough information to fully answer, respond with \"NEED_MORE_INFO: [brief explanation of what's missing]\"\n",
        "    - This is iteration {iteration} of 3.\n",
        "    \"\"\"\n",
        "\n",
        "    print(f\"ü§ñ Generating answer (iteration {iteration})...\")\n",
        "\n",
        "    response = llm.invoke([HumanMessage(content=prompt)])\n",
        "    answer = response.content\n",
        "\n",
        "    needs_more = \"NEED_MORE_INFO\" in answer\n",
        "\n",
        "    if needs_more:\n",
        "        print(f\"‚ö†Ô∏è  Answer incomplete, needs more research\")\n",
        "    else:\n",
        "        print(f\"‚úÖ Answer complete!\")\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"needs_more_info\": needs_more\n",
        "    }"
      ],
      "metadata": {
        "id": "wZE1s5DnjWuL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def should_continue_research(state: ResearchState) -> Literal[\"search\", \"end\"]:\n",
        "    \"\"\"Decides if we need to search more or finish\"\"\"\n",
        "    if state[\"needs_more_info\"] and state[\"iteration_count\"] < 3:\n",
        "        print(f\"üîÑ Looping back for more research (iteration {state['iteration_count']}/3)\")\n",
        "        return \"search\"  # Go back and search again\n",
        "    else:\n",
        "        if state[\"iteration_count\"] >= 3:\n",
        "            print(f\"‚èπÔ∏è  Max iterations reached, stopping\")\n",
        "        return \"end\"  # We're done"
      ],
      "metadata": {
        "id": "fRBUT-0HpkQ2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Graph"
      ],
      "metadata": {
        "id": "C0beFzqupwKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_research_graph():\n",
        "    \"\"\"Creates and compiles the research graph\"\"\"\n",
        "    workflow = StateGraph(ResearchState)\n",
        "\n",
        "    # Add nodes\n",
        "    workflow.add_node(\"analyze\", analyze_question)\n",
        "    workflow.add_node(\"search\", search_web)\n",
        "    workflow.add_node(\"generate\", generate_answer)\n",
        "\n",
        "    # Add edges\n",
        "    workflow.set_entry_point(\"analyze\")  # Start here\n",
        "    workflow.add_edge(\"analyze\", \"search\")  # analyze ‚Üí search\n",
        "    workflow.add_edge(\"search\", \"generate\")  # search ‚Üí generate\n",
        "\n",
        "    # Add conditional edge (the magic!)\n",
        "    workflow.add_conditional_edges(\n",
        "        \"generate\",  # From this node\n",
        "        should_continue_research,  # Use this function to decide\n",
        "        {\n",
        "            \"search\": \"analyze\",  # If needs more info, loop back\n",
        "            \"end\": END  # Otherwise, finish\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Compile the graph\n",
        "    return workflow.compile()\n",
        "\n"
      ],
      "metadata": {
        "id": "BL5AnZpupxwy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"=\" * 60)\n",
        "    print(\"LangGraph Research Assistant\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Create the graph\n",
        "    app = create_research_graph()\n",
        "\n",
        "    # Run with a sample question\n",
        "    question = \"How many episodes relaesed in Onepiece anime and chapters in manga?\"\n",
        "\n",
        "    print(f\"\\n‚ùì Question: {question}\\n\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    result = app.invoke({\n",
        "        \"question\": question,\n",
        "        \"iteration_count\": 0\n",
        "    })\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"FINAL ANSWER:\")\n",
        "    print(\"=\" * 60)\n",
        "    print(result[\"answer\"])\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"Total iterations: {result['iteration_count']}\")\n",
        "    print(\"=\" * 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKhkuchGtKuH",
        "outputId": "be726a66-b470-4707-fb27-470a506e7391"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "LangGraph Research Assistant\n",
            "============================================================\n",
            "\n",
            "‚ùì Question: How many episodes relaesed in Onepiece anime and chapters in manga?\n",
            "\n",
            "------------------------------------------------------------\n",
            "üîç Searching for: How many episodes relaesed in Onepiece anime and chapters in manga?\n",
            "‚úÖ Found results (length: 1237 chars)\n",
            "ü§ñ Generating answer (iteration 1)...\n",
            "‚ö†Ô∏è  Answer incomplete, needs more research\n",
            "üîÑ Looping back for more research (iteration 1/3)\n",
            "üîç Searching for: \"One Piece anime total episodes and manga chapters count\"\n",
            "‚úÖ Found results (length: 760 chars)\n",
            "ü§ñ Generating answer (iteration 2)...\n",
            "‚ö†Ô∏è  Answer incomplete, needs more research\n",
            "üîÑ Looping back for more research (iteration 2/3)\n",
            "üîç Searching for: One Piece anime total episodes and manga chapters count\n",
            "‚úÖ Found results (length: 1349 chars)\n",
            "ü§ñ Generating answer (iteration 3)...\n",
            "‚úÖ Answer complete!\n",
            "‚èπÔ∏è  Max iterations reached, stopping\n",
            "\n",
            "============================================================\n",
            "FINAL ANSWER:\n",
            "============================================================\n",
            "The One Piece anime has released more than 1150 episodes as of November 2025. The manga series, on the other hand, has spanned over 1168 chapters and has been compiled into 113 tank≈çbon volumes as of November 2025, although an earlier update in July 2025 reported 112 tank≈çbon volumes.\n",
            "\n",
            "============================================================\n",
            "Total iterations: 3\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}